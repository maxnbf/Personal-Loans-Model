{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import norm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition, Cleaning, and Wrangling\n",
    "\n",
    "Data was acquired from Kaggle. Downloaded into a csv file directly from this link: https://www.kaggle.com/vipin20/loan-application-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "      <th>Total_Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "      <td>$5849.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "      <td>$6091.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "      <td>$3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "      <td>$4941.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "      <td>$6000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>LP002586</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3326</td>\n",
       "      <td>913.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "      <td>$4239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>LP002587</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2600</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Y</td>\n",
       "      <td>$4300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>LP002588</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4625</td>\n",
       "      <td>2857.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "      <td>$7482.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>LP002600</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "      <td>$2895.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>LP002602</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6283</td>\n",
       "      <td>4416.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "      <td>$10699.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Loan_ID  Gender Married Dependents     Education Self_Employed  \\\n",
       "0    LP001002    Male      No          0      Graduate            No   \n",
       "1    LP001003    Male     Yes          1      Graduate            No   \n",
       "2    LP001005    Male     Yes          0      Graduate           Yes   \n",
       "3    LP001006    Male     Yes          0  Not Graduate            No   \n",
       "4    LP001008    Male      No          0      Graduate            No   \n",
       "..        ...     ...     ...        ...           ...           ...   \n",
       "495  LP002586  Female     Yes          1      Graduate            No   \n",
       "496  LP002587    Male     Yes          0  Not Graduate            No   \n",
       "497  LP002588    Male     Yes          0      Graduate            No   \n",
       "498  LP002600    Male     Yes          1      Graduate           Yes   \n",
       "499  LP002602    Male      No          0      Graduate            No   \n",
       "\n",
       "     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0               5849                0.0         NaN             360.0   \n",
       "1               4583             1508.0       128.0             360.0   \n",
       "2               3000                0.0        66.0             360.0   \n",
       "3               2583             2358.0       120.0             360.0   \n",
       "4               6000                0.0       141.0             360.0   \n",
       "..               ...                ...         ...               ...   \n",
       "495             3326              913.0       105.0              84.0   \n",
       "496             2600             1700.0       107.0             360.0   \n",
       "497             4625             2857.0       111.0              12.0   \n",
       "498             2895                0.0        95.0             360.0   \n",
       "499             6283             4416.0       209.0             360.0   \n",
       "\n",
       "     Credit_History Property_Area Loan_Status Total_Income  \n",
       "0               1.0         Urban           Y      $5849.0  \n",
       "1               1.0         Rural           N      $6091.0  \n",
       "2               1.0         Urban           Y      $3000.0  \n",
       "3               1.0         Urban           Y      $4941.0  \n",
       "4               1.0         Urban           Y      $6000.0  \n",
       "..              ...           ...         ...          ...  \n",
       "495             1.0     Semiurban           Y      $4239.0  \n",
       "496             1.0         Rural           Y      $4300.0  \n",
       "497             NaN         Urban           Y      $7482.0  \n",
       "498             1.0     Semiurban           Y      $2895.0  \n",
       "499             0.0         Rural           N     $10699.0  \n",
       "\n",
       "[500 rows x 14 columns]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('df1_loan.csv', index_col =0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was cleaned by dropping all null values and turning all qualitative data into quantitative data. For example, for marital status, *Yes* corresponds to 1, and *No* corresponds to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(419, 13)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_data(df):\n",
    "    del df[\"Loan_ID\"]\n",
    "\n",
    "    df[\"Total_Income\"]=df[\"Total_Income\"].str.replace(\"$\",\"\")\n",
    "    df[\"Total_Income\"]=df[\"Total_Income\"].apply(pd.to_numeric)\n",
    "\n",
    "    df[\"Dependents\"]=df[\"Dependents\"].str.replace('+','')\n",
    "    df[\"Dependents\"]=df[\"Dependents\"].apply(pd.to_numeric)\n",
    "\n",
    "\n",
    "    df[\"Self_Employed\"] = df[\"Self_Employed\"].astype('category').cat.codes\n",
    "    df[\"Gender\"] = df[\"Gender\"].astype('category').cat.codes\n",
    "    df[\"Married\"] = df[\"Married\"].astype('category').cat.codes\n",
    "    df[\"Education\"] = df[\"Education\"].astype('category').cat.codes\n",
    "    df[\"Property_Area\"] = df[\"Property_Area\"].astype('category').cat.codes\n",
    "    df[\"Loan_Status\"] = df[\"Loan_Status\"].astype('category').cat.codes\n",
    "\n",
    "\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df\n",
    "\n",
    "df = clean_data(df)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result of dropping null values, we can see the number of samples was reduced from 500 to 419. Additionally the Loan_ID is unnecssary for any model, thus the number of features was reduced to 13. The last data manipulation involved feature extraction. We believed that the size of a family (simply the addition of parents and dependents) and the principal per month (ratio of loan amount to its term) would be important features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxnb\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\maxnb\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "      <th>Total_Income</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Principal_Per_Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6091.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.355556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4941.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.391667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5417</td>\n",
       "      <td>4196.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9613.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.741667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>494</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3597</td>\n",
       "      <td>2157.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5754.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.330556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3326</td>\n",
       "      <td>913.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4239.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2600</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.297222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2895.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.263889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6283</td>\n",
       "      <td>4416.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10699.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.580556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>419 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
       "1         1        1         1.0          0              0             4583   \n",
       "2         1        1         0.0          0              1             3000   \n",
       "3         1        1         0.0          1              0             2583   \n",
       "4         1        0         0.0          0              0             6000   \n",
       "5         1        1         2.0          0              1             5417   \n",
       "..      ...      ...         ...        ...            ...              ...   \n",
       "494       1        1         0.0          0              0             3597   \n",
       "495       0        1         1.0          0              0             3326   \n",
       "496       1        1         0.0          1              0             2600   \n",
       "498       1        1         1.0          0              1             2895   \n",
       "499       1        0         0.0          0              0             6283   \n",
       "\n",
       "     CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "1               1508.0       128.0             360.0             1.0   \n",
       "2                  0.0        66.0             360.0             1.0   \n",
       "3               2358.0       120.0             360.0             1.0   \n",
       "4                  0.0       141.0             360.0             1.0   \n",
       "5               4196.0       267.0             360.0             1.0   \n",
       "..                 ...         ...               ...             ...   \n",
       "494             2157.0       119.0             360.0             0.0   \n",
       "495              913.0       105.0              84.0             1.0   \n",
       "496             1700.0       107.0             360.0             1.0   \n",
       "498                0.0        95.0             360.0             1.0   \n",
       "499             4416.0       209.0             360.0             0.0   \n",
       "\n",
       "     Property_Area  Loan_Status  Total_Income  Family_Size  \\\n",
       "1                0            0        6091.0          3.0   \n",
       "2                2            1        3000.0          2.0   \n",
       "3                2            1        4941.0          2.0   \n",
       "4                2            1        6000.0          1.0   \n",
       "5                2            1        9613.0          4.0   \n",
       "..             ...          ...           ...          ...   \n",
       "494              0            0        5754.0          2.0   \n",
       "495              1            1        4239.0          3.0   \n",
       "496              0            1        4300.0          2.0   \n",
       "498              1            1        2895.0          3.0   \n",
       "499              0            0       10699.0          1.0   \n",
       "\n",
       "     Principal_Per_Month  \n",
       "1               0.355556  \n",
       "2               0.183333  \n",
       "3               0.333333  \n",
       "4               0.391667  \n",
       "5               0.741667  \n",
       "..                   ...  \n",
       "494             0.330556  \n",
       "495             1.250000  \n",
       "496             0.297222  \n",
       "498             0.263889  \n",
       "499             0.580556  \n",
       "\n",
       "[419 rows x 15 columns]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fam_size(df):\n",
    "    fam_size = []\n",
    "    for m, d in zip(df[\"Married\"], df[\"Dependents\"]):\n",
    "        fam_size.append(1 + m + d)\n",
    "    \n",
    "    df[\"Family_Size\"] = fam_size\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def principal_per_month(df):\n",
    "    principal_per_month = []\n",
    "    for la, lat in zip(df[\"LoanAmount\"], df[\"Loan_Amount_Term\"]):\n",
    "        principal_per_month.append(la / lat)\n",
    "    \n",
    "    df[\"Principal_Per_Month\"] = principal_per_month\n",
    "\n",
    "    return df\n",
    "\n",
    "df = principal_per_month(fam_size(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above can be seen the two extra features in the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we used two different algorithms to select the most important features from the DataFrame. The two algorithms used were SelectKBest and RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_best_features(k, features, target):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=3000)\n",
    "  \n",
    "    selector = SelectKBest(f_regression, k = k)\n",
    "    selector.fit(X_train, y_train)\n",
    "\n",
    "    selected = selector.get_support()\n",
    "  \n",
    "    columns = []\n",
    "    for i in range(len(selected)):\n",
    "        if selected[i]:\n",
    "            columns.append(df.columns[i])\n",
    "\n",
    "    return columns\n",
    "\n",
    "def random_forest_selection(k, features, target):\n",
    "    X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(features, target, random_state=1000)\n",
    "\n",
    "    model = RandomForestRegressor(max_depth=10, random_state=1000)\n",
    "    model.fit(X_train_reg,y_train_reg)\n",
    "\n",
    "    reg_columns = df.columns\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[-k:]  # top 5 features\n",
    "\n",
    "    plt.title('Regression Feature Importances')\n",
    "    plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "    plt.yticks(range(len(indices)), [reg_columns[i] for i in indices])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_target(k_best=None):\n",
    "\n",
    "    target_column = f\"Loan_Status\"\n",
    "    target = df[target_column].dropna()\n",
    "\n",
    "    df2 = df.copy()\n",
    "    del df2[target_column]\n",
    "\n",
    "    if k_best is not None:\n",
    "        # if the k_best are requested, use the k_best_features function to select the best features and filter\n",
    "        selected_names = k_best_features(k_best, df2, target)\n",
    "        df2 = df.loc[df[target_column].notna(), selected_names]\n",
    "        \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df2)\n",
    "    df2 = scaler.transform(df2)\n",
    "\n",
    "    return df2, target\n",
    "\n",
    "features, target = get_features_target()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the top 5 features using each algorithm returns 4 of the same 5 features. Then we separated the features from the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Education', 'LoanAmount', 'Credit_History', 'Property_Area', 'Family_Size']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_features = 5\n",
    "print(k_best_features(num_features, features, target))\n",
    "random_forest_selection(num_features, features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(f1, xlim, f2, ylim, target):\n",
    "    x_t0 = []\n",
    "    x_t1 = []\n",
    "    for x1, x2, y in zip(df[f1], df[f2], target):\n",
    "        if y == 0:\n",
    "            x_t0.append([x1, x2])\n",
    "        else:\n",
    "            x_t1.append([x1, x2])\n",
    "    \n",
    "    x_t0 = np.array(x_t0)\n",
    "    x_t1 = np.array(x_t1)\n",
    "\n",
    "    plt.scatter(x_t0[:,0], x_t0[:,1], color='red', label='No', marker='o')\n",
    "    plt.scatter(x_t1[:,0], x_t1[:,1], color='green', label='Yes', marker=\"o\")\n",
    "\n",
    "  \n",
    "    plt.legend()\n",
    "    plt.xlabel(f1)\n",
    "    plt.ylabel(f2)\n",
    "    ax = plt.gca()\n",
    "    ax.autoscale(False)\n",
    "\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim(ylim)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#plot_data(\"LoanAmount\", [0, 350], \"ApplicantIncome\", [0, 20000], target)\n",
    "#plot_data(\"Credit_History\", [-.5, 1.5], \"ApplicantIncome\", [0, 20000], target)\n",
    "#plot_data(\"LoanAmount\", [0, 350], \"Family_Size\", [0, 6], target)\n",
    "\n",
    "#\n",
    "# SHOULD CONSIDER MAKING Line/Bar graphs where x axis is a feature and y axis is percent of loans accepted at that feature value. This is for the features with only values of 0,1,2,3\n",
    "#\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_axes([0,0,1,1])\n",
    "# ax.bar(df[\"Family_Size\"], perc_target)\n",
    "# plt.show()\n",
    "\n",
    "# for i in range(5):\n",
    "#     #fam_size = df.loc[df[\"Family_Size\"] == i, target]\n",
    "#     iter = \"Family_Size == \" + str(i)\n",
    "#     fam_size = df.query(iter)\n",
    "#     perc_target = sum(fam_size) / len(fam_size)\n",
    "\n",
    "# #print(perc_target)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model\n",
    "\n",
    "4 different classifiers will be used to trian and test the model:\n",
    "    - Neural Network\n",
    "    - SVM\n",
    "    - Logistic Regressor\n",
    "    - Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device: ', device)\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_size, activations):\n",
    "        super().__init__()\n",
    "            \n",
    "        assert len(hidden_size) > 0\n",
    "        act = {'sigmoid': nn.Sigmoid(), 'tanh': nn.Tanh(), 'relu': nn.ReLU(), 'identity': nn.Identity()}\n",
    "        \n",
    "        self.layers = []\n",
    "        for i in range(n_layers - 1):\n",
    "            self.layers.append(nn.Linear(hidden_size[i], hidden_size[i + 1]))\n",
    "            if activations[i] in act:\n",
    "                self.layers.append(act[activations[i]])\n",
    "            else:\n",
    "                assert activations in ['sigmoid', 'tanh', 'relu', 'identity']\n",
    "        \n",
    "        self.layers = nn.ModuleList(self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for idx in range(len(self.layers) - 1):\n",
    "            x = self.layers[idx](x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(model, optimizer, criterion, n_epoch, data, label):\n",
    "    data = torch.tensor(data, dtype=torch.float).to(device)\n",
    "\n",
    "    label = label.tolist()\n",
    "    label = torch.tensor(label, dtype=torch.long).squeeze().to(device)\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        predict = model(data)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(predict, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model.named_parameters\n",
    "\n",
    "def model_accuracy(model, data, label):\n",
    "    data = torch.tensor(data, dtype=torch.float).to(device)\n",
    "    \n",
    "    predict = model(data)\n",
    "    predict = torch.argmax(predict, dim=-1).cpu().detach().numpy()\n",
    "    acc = accuracy_score(predict, label)\n",
    "\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Setting -------------------\n",
      "hidden layer = 1, neuron = 50\n",
      "Train Accuracy:  0.8089171974522293\n",
      "Test Accuracy:  0.8285714285714286\n",
      "---------------- Setting -------------------\n",
      "hidden layer = 2, neuron = 30, 30\n",
      "Train Accuracy:  0.8439490445859873\n",
      "Test Accuracy:  0.7428571428571429\n",
      "---------------- Setting -------------------\n",
      "hidden layer = 2, neuron = 40, 40\n",
      "Train Accuracy:  0.8057324840764332\n",
      "Test Accuracy:  0.7904761904761904\n",
      "---------------- Setting -------------------\n",
      "hidden layer = 2, neuron = 50, 50\n",
      "Train Accuracy:  0.8057324840764332\n",
      "Test Accuracy:  0.780952380952381\n",
      "---------------- Setting -------------------\n",
      "hidden layer = 2, neuron = 100, 100\n",
      "Train Accuracy:  0.7101910828025477\n",
      "Test Accuracy:  0.7523809523809524\n",
      "---------------- Setting -------------------\n",
      "hidden layer = 3, neuron = 50, 50, 50\n",
      "Train Accuracy:  0.7707006369426752\n",
      "Test Accuracy:  0.8\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 2000\n",
    "learning_rate = 0.1\n",
    "settings = {\n",
    "'hidden layer = 1, neuron = 50': {'hs': [14, 50, 2], 'act': ['identity','relu', 'sigmoid']},\n",
    "'hidden layer = 2, neuron = 30, 30': {'hs': [14, 30, 30, 2], 'act':['identity', 'relu', 'relu', 'sigmoid']},\n",
    "'hidden layer = 2, neuron = 40, 40': {'hs': [14, 40, 40, 2], 'act':['identity', 'relu', 'relu', 'sigmoid']},\n",
    "'hidden layer = 2, neuron = 50, 50': {'hs': [14, 50, 50, 2], 'act':['identity', 'relu', 'relu', 'sigmoid']},\n",
    "'hidden layer = 2, neuron = 100, 100': {'hs': [14, 100, 100, 2], 'act':['identity', 'relu', 'relu', 'sigmoid']},\n",
    "'hidden layer = 3, neuron = 50, 50, 50': {'hs': [14, 50, 50, 50, 2], 'act':['identity', 'relu', 'relu', 'relu', 'sigmoid']}}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=3000)\n",
    "  \n",
    "\n",
    "for setting in settings:\n",
    "    print('---------------- Setting -------------------')\n",
    "    print(setting)\n",
    "\n",
    "    n_layers = len(settings[setting]['hs'])\n",
    "    hidden_size = settings[setting]['hs']\n",
    "    activations = settings[setting]['act']\n",
    "\n",
    "    model = NN(n_layers, hidden_size, activations).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    param = train_nn(model, optimizer, criterion, n_epoch, X_train, y_train)\n",
    "\n",
    "    print('Train Accuracy: ', model_accuracy(model, X_train, y_train))\n",
    "    print('Test Accuracy: ', model_accuracy(model, X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def train_logistic_regressor(features, target):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target)\n",
    "    \n",
    "    solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "    penalty =  ['l1','l2', 'elasticnet']\n",
    "    c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "\n",
    "\n",
    "    grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    grid_search = GridSearchCV(estimator=LogisticRegression(), param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "\n",
    "    grid_result = grid_search.fit(X_train, y_train)\n",
    "  \n",
    "    print(\"Best params\", grid_result.best_params_)\n",
    "\n",
    "    data_rows = []\n",
    "    total_score = 0\n",
    "    iters = 10\n",
    "    for i in range(iters):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features, target)\n",
    "        model = LogisticRegression(max_iter=20000, **grid_result.best_params_).fit(X_train, y_train)\n",
    "\n",
    "        train_acc = model.score(X_train, y_train)\n",
    "        test_acc = model.score(X_test, y_test)\n",
    "\n",
    "        total_score += test_acc\n",
    "\n",
    "        data_rows.append({\n",
    "            \"train_acc\": train_acc,\n",
    "            \"test_acc\": test_acc\n",
    "        })\n",
    "\n",
    "    test_df = pd.DataFrame(data_rows)\n",
    "    print('average score', total_score/iters, '\\n',test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SVM(features, target):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target)\n",
    "    \n",
    "    kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    c_values = [50, 10, 1.0, 0.1, 0.01]\n",
    "    gamma = ['scale', 'auto']\n",
    "\n",
    "    grid = dict(kernel=kernel,C=c_values,gamma=gamma)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    grid_search = GridSearchCV(estimator=SVC(), param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "\n",
    "    grid_result = grid_search.fit(X_train, y_train)\n",
    "  \n",
    "    print(\"Best params\", grid_result.best_params_)\n",
    "\n",
    "    data_rows = []\n",
    "    total_score = 0\n",
    "    iters = 10\n",
    "    for i in range(iters):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features, target)\n",
    "        model = SVC(max_iter=20000, **grid_result.best_params_).fit(X_train, y_train)\n",
    "\n",
    "        train_acc = model.score(X_train, y_train)\n",
    "        test_acc = model.score(X_test, y_test)\n",
    "\n",
    "        total_score += test_acc\n",
    "\n",
    "        data_rows.append({\n",
    "            \"train_acc\": train_acc,\n",
    "            \"test_acc\": test_acc\n",
    "        })\n",
    "\n",
    "    test_df = pd.DataFrame(data_rows)\n",
    "    print('average score', total_score/iters, '\\n',test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "average score 0.8114285714285714 \n",
      "    train_acc  test_acc\n",
      "0   0.808917  0.800000\n",
      "1   0.796178  0.838095\n",
      "2   0.805732  0.809524\n",
      "3   0.815287  0.780952\n",
      "4   0.808917  0.800000\n",
      "5   0.808917  0.800000\n",
      "6   0.802548  0.819048\n",
      "7   0.802548  0.819048\n",
      "8   0.808917  0.800000\n",
      "9   0.792994  0.847619\n",
      "Best params {'C': 1.0, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "average score 0.7952380952380952 \n",
      "    train_acc  test_acc\n",
      "0   0.786624  0.790476\n",
      "1   0.799363  0.771429\n",
      "2   0.761146  0.819048\n",
      "3   0.786624  0.800000\n",
      "4   0.764331  0.866667\n",
      "5   0.796178  0.780952\n",
      "6   0.789809  0.742857\n",
      "7   0.792994  0.752381\n",
      "8   0.780255  0.800000\n",
      "9   0.783439  0.828571\n"
     ]
    }
   ],
   "source": [
    "train_logistic_regressor(features, target)\n",
    "train_SVM(features, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(419, 4)\n",
      "Best params {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "average score 0.8257142857142856 \n",
      "    train_acc  test_acc\n",
      "0   0.792994  0.847619\n",
      "1   0.812102  0.790476\n",
      "2   0.789809  0.857143\n",
      "3   0.805732  0.809524\n",
      "4   0.802548  0.819048\n",
      "5   0.799363  0.828571\n",
      "6   0.786624  0.866667\n",
      "7   0.808917  0.800000\n",
      "8   0.802548  0.819048\n",
      "9   0.802548  0.819048\n",
      "Best params {'C': 50, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "average score 0.8066666666666666 \n",
      "    train_acc  test_acc\n",
      "0   0.802548  0.819048\n",
      "1   0.808917  0.800000\n",
      "2   0.812102  0.790476\n",
      "3   0.805732  0.809524\n",
      "4   0.815287  0.780952\n",
      "5   0.815287  0.780952\n",
      "6   0.799363  0.828571\n",
      "7   0.812102  0.790476\n",
      "8   0.789809  0.857143\n",
      "9   0.805732  0.809524\n"
     ]
    }
   ],
   "source": [
    "features, target = get_features_target(k_best = 4)\n",
    "print(features.shape)\n",
    "train_logistic_regressor(features, target)\n",
    "train_SVM(features, target)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf81c6e26478d1c30591ba7e2b0f5435dda96e3b5f4bb1bb7824f3f9f5ac3a2c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
